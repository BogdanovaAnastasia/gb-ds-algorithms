{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание к уроку \"Урок 1. Алгоритм линейной регрессии. Градиентный спуск\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huXrhXQsZTMt"
   },
   "source": [
    "**1. Подберите скорость обучения (alpha) и количество итераций**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTSC2cFnCd8T"
   },
   "outputs": [],
   "source": [
    "def calc_mse(y, y_pred):\n",
    "    err = np.mean((y - y_pred)**2) # <=> 1/n * np.sum((y_pred - y)**2)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
       "       [ 1,  1,  2,  5,  3,  0,  5, 10,  1,  2]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "              [1, 1, 2, 5, 3, 0, 5, 10, 1, 2]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[45, 55, 50, 55, 60, 35, 75, 80, 50, 60]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [45, 55, 50, 55, 60, 35, 75, 80, 50, 60]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "IDB22MQKMYaJ",
    "outputId": "4c03219e-a57c-4583-f439-6699fd0619bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [ 6.67106886 10.61676385], MSE = 749.71\n",
      "Iteration #20: W_new = [ 9.49320908 10.25731657], MSE = 648.91\n",
      "Iteration #30: W_new = [11.85740092  9.83349244], MSE = 570.46\n",
      "Iteration #40: W_new = [13.86876921  9.46898661], MSE = 508.03\n",
      "Iteration #50: W_new = [15.59085668  9.15672679], MSE = 457.73\n",
      "Iteration #60: W_new = [17.07337653  8.88789585], MSE = 416.77\n",
      "Iteration #70: W_new = [18.35601294  8.65530964], MSE = 383.06\n",
      "Iteration #80: W_new = [19.47073522  8.45317196], MSE = 355.08\n",
      "Iteration #90: W_new = [20.44350656  8.27677488], MSE = 331.65\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 1e-2 \n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {alpha} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(100):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "    for k in range(W.shape[0]):\n",
    "        W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
    "    if i % 10 == 0:\n",
    "        alpha /= 1.1\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_decent(alpha=1e-2, iters=100):\n",
    "    n = X.shape[1]\n",
    "    W = np.array([1, 0.5])\n",
    "    print(f'Number of objects = {n} \\\n",
    "           \\nLearning rate = {alpha} \\\n",
    "           \\nInitial weights = {W} \\n')\n",
    "\n",
    "    for i in range(iters):\n",
    "        y_pred = np.dot(W, X)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        for k in range(W.shape[0]):\n",
    "            W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
    "        if i % 10 == 0:\n",
    "            alpha /= 1.1\n",
    "            print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вектор W_new перестаёт меняться на 3-ьем - 4-ом знаке после запятой\n",
    "# для большей точности можно увеличить количество итераций\n",
    "# если ещё увеличить альфа, то перескакиваем через нужные значения\n",
    "# если уменьшить альфа, то скорость схождения вектора становится медленнее\n",
    "alpha = 1e-1\n",
    "iters = 351"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10            \n",
      "Learning rate = 0.1            \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [11.8 38.2], MSE = 3047.75\n",
      "Iteration #10: W_new = [12651.73553914 69617.0969639 ], MSE = 18310954068.05\n",
      "Iteration #20: W_new = [ 7732434.81888022 42641607.3785219 ], MSE = 9128819654907584.0\n",
      "Iteration #30: W_new = [1.06344502e+09 5.86454589e+09], MSE = 2.3279203642668515e+20\n",
      "Iteration #40: W_new = [3.00127077e+10 1.65510116e+11], MSE = 2.5451335298159486e+23\n",
      "Iteration #50: W_new = [1.55345341e+11 8.56677968e+11], MSE = 9.572295620500124e+24\n",
      "Iteration #60: W_new = [1.27742291e+11 7.04456313e+11], MSE = 9.351480126476035e+24\n",
      "Iteration #70: W_new = [1.38141953e+10 7.61806995e+10], MSE = 1.6408589528283986e+23\n",
      "Iteration #80: W_new = [1.51674189e+08 8.36432543e+08], MSE = 3.125533537874479e+19\n",
      "Iteration #90: W_new = [116395.49978363 641638.79866064], MSE = 31317286806394.58\n",
      "Iteration #100: W_new = [48.41959619 22.99885147], MSE = 53518.86\n",
      "Iteration #110: W_new = [44.97711111  3.82799209], MSE = 43.97\n",
      "Iteration #120: W_new = [44.99891751  3.8240297 ], MSE = 43.97\n",
      "Iteration #130: W_new = [45.01385183  3.8213216 ], MSE = 43.97\n",
      "Iteration #140: W_new = [45.02434994  3.81941793], MSE = 43.97\n",
      "Iteration #150: W_new = [45.03190658  3.81804765], MSE = 43.97\n",
      "Iteration #160: W_new = [45.03746405  3.81703988], MSE = 43.97\n",
      "Iteration #170: W_new = [45.04163168  3.81628415], MSE = 43.97\n",
      "Iteration #180: W_new = [45.04481278  3.8157073 ], MSE = 43.97\n",
      "Iteration #190: W_new = [45.04728014  3.81525989], MSE = 43.97\n",
      "Iteration #200: W_new = [45.04922195  3.81490777], MSE = 43.97\n",
      "Iteration #210: W_new = [45.05077048  3.81462697], MSE = 43.97\n",
      "Iteration #220: W_new = [45.05202029  3.81440033], MSE = 43.97\n",
      "Iteration #230: W_new = [45.05304003  3.81421542], MSE = 43.97\n",
      "Iteration #240: W_new = [45.05388032  3.81406305], MSE = 43.97\n",
      "Iteration #250: W_new = [45.05457899  3.81393635], MSE = 43.97\n",
      "Iteration #260: W_new = [45.05516467  3.81383015], MSE = 43.97\n",
      "Iteration #270: W_new = [45.05565927  3.81374046], MSE = 43.97\n",
      "Iteration #280: W_new = [45.05607977  3.81366421], MSE = 43.97\n",
      "Iteration #290: W_new = [45.05643948  3.81359898], MSE = 43.97\n",
      "Iteration #300: W_new = [45.05674888  3.81354288], MSE = 43.97\n",
      "Iteration #310: W_new = [45.05701637  3.81349437], MSE = 43.97\n",
      "Iteration #320: W_new = [45.05724868  3.81345225], MSE = 43.97\n",
      "Iteration #330: W_new = [45.05745128  3.81341551], MSE = 43.97\n",
      "Iteration #340: W_new = [45.05762864  3.81338335], MSE = 43.97\n",
      "Iteration #350: W_new = [45.05778444  3.81335509], MSE = 43.97\n"
     ]
    }
   ],
   "source": [
    "gradient_decent(alpha, iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Qu1o4JhZYwI"
   },
   "source": [
    "***2. В этом коде мы избавляемся от итераций по весам, но тут есть ошибка, исправьте ее**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [5.85 5.35], MSE = 3047.75\n",
      "Iteration #10: W_new = [11.0965715 10.5965715], MSE = 597.49\n",
      "Iteration #20: W_new = [11.10415569 10.60415569], MSE = 597.49\n",
      "Iteration #30: W_new = [11.10416665 10.60416665], MSE = 597.49\n",
      "Iteration #40: W_new = [11.10416667 10.60416667], MSE = 597.49\n",
      "Iteration #50: W_new = [11.10416667 10.60416667], MSE = 597.49\n",
      "Iteration #60: W_new = [11.10416667 10.60416667], MSE = 597.49\n",
      "Iteration #70: W_new = [11.10416667 10.60416667], MSE = 597.49\n",
      "Iteration #80: W_new = [11.10416667 10.60416667], MSE = 597.49\n",
      "Iteration #90: W_new = [11.10416667 10.60416667], MSE = 597.49\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 1e-2\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {alpha} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(100):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#     for k in range(W.shape[0]):\n",
    "#         W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
    "    W -= alpha * (1/n * 2 * np.sum(X * (y_pred - y)))\n",
    "    W_pred = W\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "WZZzDCQLY4pA",
    "outputId": "28f58ade-72f2-4381-809d-2417752d56e4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10        \n",
      "Learning rate = 0.01        \n",
      "Initial weights = [1.  0.5] \n",
      "\n",
      "Iteration #0: W_new = [2.08 4.27], MSE = 3047.75\n",
      "Iteration #10: W_new = [ 7.0011236 10.6169007], MSE = 738.65\n",
      "Iteration #20: W_new = [10.3486292  10.10603105], MSE = 622.03\n",
      "Iteration #30: W_new = [13.38789582  9.55618391], MSE = 525.24\n",
      "Iteration #40: W_new = [16.16088505  9.05336203], MSE = 444.66\n",
      "Iteration #50: W_new = [18.69110735  8.59454545], MSE = 377.58\n",
      "Iteration #60: W_new = [20.99981865  8.17589626], MSE = 321.72\n",
      "Iteration #70: W_new = [23.10641138  7.79389815], MSE = 275.22\n",
      "Iteration #80: W_new = [25.02858024  7.44534246], MSE = 236.5\n",
      "Iteration #90: W_new = [26.78247081  7.12730145], MSE = 204.27\n"
     ]
    }
   ],
   "source": [
    "n = X.shape[1]\n",
    "alpha = 1e-2\n",
    "W = np.array([1, 0.5])\n",
    "print(f'Number of objects = {n} \\\n",
    "       \\nLearning rate = {alpha} \\\n",
    "       \\nInitial weights = {W} \\n')\n",
    "\n",
    "for i in range(100):\n",
    "    y_pred = np.dot(W, X)\n",
    "    err = calc_mse(y, y_pred)\n",
    "#     for k in range(W.shape[0]):\n",
    "#         W[k] -= alpha * (1/n * 2 * np.sum(X[k] * (y_pred - y)))\n",
    "    W -= alpha * (1/n * 2 * (X @ (y_pred - y)))\n",
    "    W_pred = W\n",
    "    if i % 10 == 0:\n",
    "        print(f'Iteration #{i}: W_new = {W}, MSE = {round(err,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужно убрать сумму, так как произведение векторов уже содержит в себе сумму по элементам строк X и использовать произведение векторов (матриц)\n",
    "# для перемножения вектора X и вектора, получившегося в результате разности реального и предсказываемого векторов y\n",
    "# \n",
    "# если подставить изменения альфа из предыдущего задания, то результаты будут те же (как проверка)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание *3 (доп.): вместо того, чтобы задавать количество итераций, задайте условие остановки алгоритма - когда ошибка за итерацию начинает изменяться ниже определенного порога (упрощенный аналог параметра tol в линейной регрессии в sklearn).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_wo_iterations(ε=0.001):\n",
    "    n = X.shape[1]\n",
    "    alpha = 1e-2\n",
    "    W = np.array([1, 0.5])\n",
    "    print(f'Number of objects = {n} \\\n",
    "           \\nLearning rate = {alpha} \\\n",
    "           \\nInitial weights = {W} \\\n",
    "           \\nε = {ε}\\n')\n",
    "    i = 0\n",
    "\n",
    "    while(True):\n",
    "        y_pred = np.dot(W, X)\n",
    "        current_err = calc_mse(y, y_pred)\n",
    "        current_W = W\n",
    "        W -= alpha * (1/n * 2 * (X @ (y_pred - y)))\n",
    "        y_pred = np.dot(W, X)\n",
    "        err = calc_mse(y, y_pred)\n",
    "        i += 1\n",
    "        if abs(err - current_err) < ε:\n",
    "            break\n",
    "    print(f'Iteration #{i-1}: W_new = {current_W}, MSE = {current_err}\\n\\\n",
    "Iteration #{i}: W_new = {W}, MSE = {err}') if i % 10 != 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10            \n",
      "Learning rate = 0.01            \n",
      "Initial weights = [1.  0.5]            \n",
      "ε = 0.001\n",
      "\n",
      "Iteration #526: W_new = [44.72585318  3.87354571], MSE = 44.02311494252028\n",
      "Iteration #527: W_new = [44.72585318  3.87354571], MSE = 44.02212785581047\n"
     ]
    }
   ],
   "source": [
    "gradient_descent_wo_iterations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10            \n",
      "Learning rate = 0.01            \n",
      "Initial weights = [1.  0.5]            \n",
      "ε = 0.0001\n",
      "\n",
      "Iteration #651: W_new = [44.95539458  3.83192192], MSE = 43.97425291503393\n",
      "Iteration #652: W_new = [44.95539458  3.83192192], MSE = 43.97415300038226\n"
     ]
    }
   ],
   "source": [
    "gradient_descent_wo_iterations(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects = 10            \n",
      "Learning rate = 0.01            \n",
      "Initial weights = [1.  0.5]            \n",
      "ε = 1e-05\n",
      "\n",
      "Iteration #777: W_new = [45.02873479  3.8186228 ], MSE = 43.96929690119503\n",
      "Iteration #778: W_new = [45.02873479  3.8186228 ], MSE = 43.96928697128659\n"
     ]
    }
   ],
   "source": [
    "gradient_descent_wo_iterations(0.00001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
